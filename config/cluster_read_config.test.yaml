- name: measurements.cluster_cpu_usage_seconds_total_rate
  monitoring_query: sum(node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate{cluster=""})
  monitoring_step: 15

- name: measurements.cluster_memory_usage_rss_total
  monitoring_query: sum(container_memory_rss{job="kubelet", metrics_path="/metrics/cadvisor", cluster="", container!=""})
  monitoring_step: 15

- name: measurements.cluster_disk_throughput_total
  monitoring_query: sum (rate(container_fs_reads_bytes_total{id!="", device=~"(/dev.+)|mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+", cluster=""}[5m]) + rate(container_fs_writes_bytes_total{id!="", device=~"(/dev.+)|mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+", cluster=""}[5m]))
  monitoring_step: 15

- name: measurements.cluster_network_bytes_total
  monitoring_query: sum(irate(container_network_receive_bytes_total{cluster="",namespace=~".*"}[5m])) + sum(irate(container_network_transmit_bytes_total{cluster="",namespace=~".*"}[5m]))
  monitoring_step: 15

- name: measurements.cluster_network_receive_bytes_total
  monitoring_query: sum(irate(container_network_receive_bytes_total{cluster="",namespace=~".*"}[5m]))
  monitoring_step: 15

- name: measurements.cluster_network_transmit_bytes_total
  monitoring_query: sum(irate(container_network_transmit_bytes_total{cluster="",namespace=~".*"}[5m]))
  monitoring_step: 15

- name: measurements.node_disk_io_time_seconds_total
  monitoring_query: sum(irate(node_disk_io_time_seconds_total{cluster="",namespace=~".*"}[5m]))
  monitoring_step: 15

- name: measurements.cluster_nodes_worker_count
  monitoring_query: count(kube_node_role{role="worker"})
  monitoring_step: 15

- name: measurements.cluster_pods_count
  monitoring_query: count(kube_pod_info)
  monitoring_step: 15

- name: measurements.cluster_running_pods_on_workers_count
  monitoring_query: count(kube_pod_info * on(node) group_left(role) kube_node_role{role="worker"} and on(pod, namespace) (kube_pod_status_phase{job="kube-state-metrics", phase="Running"} > 0))
  monitoring_step: 15

- name: measurements.etcd_request_duration_seconds_average
  monitoring_query: sum(rate(etcd_request_duration_seconds_sum{}[5m])) / sum(rate(etcd_request_duration_seconds_count[5m]))
  monitoring_step: 15



# Interesting CI environment variables
{% for var in [
  'BUILD_ID',
  'HOSTNAME',
  'JOB_NAME',
  'OPENSHIFT_API',
  'PROW_JOB_ID',
  'PULL_BASE_REF',
  'PULL_BASE_SHA',
  'PULL_HEAD_REF',
  'PULL_NUMBER',
  'PULL_PULL_SHA',
  'PULL_REFS',
  'REPO_NAME',
  'REPO_OWNER',
  'USERS',
  'WORKERS',
  'DURATION',
  'SPAWN_RATE',
  'SCENARIO',
  'PRE_LOAD_DB',
  'RHDH_DEPLOYMENT_REPLICAS',
  'RHDH_DB_REPLICAS',
  'RHDH_DB_STORAGE',
  'RHDH_RESOURCES_CPU_REQUESTS',
  'RHDH_RESOURCES_CPU_LIMITS',
  'RHDH_RESOURCES_MEMORY_REQUESTS',
  'RHDH_RESOURCES_MEMORY_LIMITS',
  'RHDH_KEYCLOAK_REPLICAS',
  'RHDH_HELM_REPO',
  'RHDH_HELM_CHART',
  'RHDH_HELM_CHART_VERSION',
  'RHDH_HELM_RELEASE_NAME',
  'RHDH_IMAGE_REGISTRY',
  'RHDH_IMAGE_REPO',
  'RHDH_IMAGE_TAG',
  'API_COUNT',
  'COMPONENT_COUNT',
  'BACKSTAGE_USER_COUNT',
  'GROUP_COUNT',
  'WAIT_FOR_SEARCH_INDEX',
  'SCALE_WORKERS',
  'SCALE_ACTIVE_USERS_SPAWN_RATES',
  'SCALE_BS_USERS_GROUPS',
  'SCALE_CATALOG_SIZES',
  'SCALE_REPLICAS',
  'SCALE_DB_STORAGES'
] %}
- name: metadata.env.{{ var }}
  env_variable: {{ var }}
{% endfor %}

- name: metadata.git.last_commit.hash
  command: git log -1 --pretty=format:"%H"



# Gather some basic info about the cluster
- name: metadata.cluster.context
  command: oc project default > /dev/null && oc config current-context

- name: metadata.cluster.control-plane.count
  command: oc get nodes -l node-role.kubernetes.io/master -o name | wc -l

- name: metadata.cluster.control-plane.flavor
  command: oc get nodes -l node-role.kubernetes.io/master -o json | jq --raw-output '.items | map(.metadata.labels."beta.kubernetes.io/instance-type") | unique | sort | join(",")'

- name: metadata.cluster.control-plane.nodes
  command: oc get nodes -l node-role.kubernetes.io/master -o json | jq '.items | map(.metadata.name)'
  output: json

- name: metadata.cluster.compute-nodes.count
  command: oc get nodes -l node-role.kubernetes.io/worker -o name | wc -l

- name: metadata.cluster.compute-nodes.flavor
  command: oc get nodes -l node-role.kubernetes.io/worker -o json | jq --raw-output '.items | map(.metadata.labels."beta.kubernetes.io/instance-type") | unique | sort | join(",")'

- name: metadata.cluster.compute-nodes.nodes
  command: oc get nodes -l node-role.kubernetes.io/worker -o json | jq '.items | map(.metadata.name)'
  output: json



{% macro monitor_pod(namespace, pod, step=15, pod_suffix_regex='-[0-9a-f]+-.*') -%}
# Gather monitoring data about the pod
- name: measurements.{{ pod }}.cpu
  monitoring_query: sum(pod:container_cpu_usage:sum{namespace='{{ namespace }}', pod=~'{{ pod }}{{ pod_suffix_regex }}'})
  monitoring_step: {{ step }}
- name: measurements.{{ pod }}.memory
  monitoring_query: sum(container_memory_usage_bytes{namespace='{{ namespace }}', pod=~'{{ pod }}{{ pod_suffix_regex }}', container!='POD', container!=''})
  monitoring_step: {{ step }}
- name: measurements.{{ pod }}.network_throughput
  monitoring_query: sum( rate(container_network_transmit_bytes_total{namespace='{{ namespace }}', pod=~'{{ pod }}{{ pod_suffix_regex }}'}[{{ step * 4 }}s]) + rate(container_network_receive_bytes_total{namespace='{{ namespace }}', pod=~'{{ pod }}{{ pod_suffix_regex }}'}[{{ step * 4 }}s]) )
  monitoring_step: {{ step * 4 }}
- name: measurements.{{ pod }}.network_drop
  monitoring_query: sum( rate(container_network_transmit_packets_dropped_total{namespace='{{ namespace }}', pod=~'{{ pod }}{{ pod_suffix_regex }}'}[{{ step * 4 }}s]) + rate(container_network_receive_packets_dropped_total{namespace='{{ namespace }}', pod=~'{{ pod }}{{ pod_suffix_regex }}'}[{{ step * 4 }}s]) )
  monitoring_step: {{ step * 4 }}
- name: measurements.{{ pod }}.disk_throughput
  monitoring_query: sum( sum(rate(container_fs_reads_bytes_total{namespace='{{ namespace }}', pod=~'{{ pod }}{{ pod_suffix_regex }}', device!='/dev/dm-0'}[{{ step * 4 }}s])) + sum(rate(container_fs_writes_bytes_total{namespace='{{ namespace }}', pod=~'{{ pod }}{{ pod_suffix_regex }}', device!='/dev/dm-0'}[{{ step * 4 }}s])) )
  monitoring_step: {{ step * 4 }}
- name: measurements.{{ pod }}.restarts
  monitoring_query: sum(kube_pod_container_status_restarts_total{namespace='{{ namespace }}', pod=~'{{ pod }}{{ pod_suffix_regex }}'})
  monitoring_step: {{ step }}
- name: measurements.{{ pod }}.count_ready
  monitoring_query: sum( kube_pod_status_ready{namespace='{{ namespace }}', pod=~'{{ pod }}{{ pod_suffix_regex }}'} )
  monitoring_step: {{ step }}
{%- endmacro %}

{% macro pod_info(namespace, deployment, container) -%}
# Gather info about pod configuration
- name: metadata.cluster.pods.{{ deployment }}-{{ container }}.count
  command: oc -n {{ namespace }} get deployment/{{ deployment }} -o json | jq '.spec | if has("replicas") then .replicas else 1 end'
- name: metadata.cluster.pods.{{ deployment }}-{{ container }}.resources
  command: oc -n {{ namespace }} get deployment/{{ deployment }} -o json | jq '.spec.template.spec.containers | map(select(.name == "{{ container }}"))[0].resources'
  output: json
- name: metadata.cluster.pods.{{ deployment }}-{{ container }}.image
  command: oc -n {{ namespace }} get deployment/{{ deployment }} -o json | jq --raw-output '.spec.template.spec.containers | map(select(.name == "{{ container }}"))[0].image'
- name: metadata.cluster.pods.{{ deployment }}-{{ container }}.image_tag
  command: oc -n {{ namespace }} get deployment/{{ deployment }} -o json | jq --raw-output '.spec.template.spec.containers | map(select(.name == "{{ container }}"))[0].image | split(":")[1]'
{%- endmacro %}



# Collect data for relevant pods
{{ monitor_pod('rhdh-performance', 'rhdh-developer-hub', 15) }}
{{ monitor_pod('rhdh-performance', 'rhdh-postgresql', 15, '-.*') }}
{{ pod_info('rhdh-performance', 'rhdh-developer-hub', 'backstage-backend') }}



# Collect data for API pods
{{ monitor_pod('openshift-apiserver', 'apiserver', 15) }}
{{ monitor_pod('openshift-kube-apiserver', 'kube-apiserver', 15, pod_suffix_regex='-ip-.+') }}

{% macro pv_stats(pvc) -%}
# Collect data for PV stats
- name: measurements.cluster.pv_stats.test.{{pvc}}.capacity_bytes
  monitoring_query: kubelet_volume_stats_capacity_bytes{persistentvolumeclaim="{{ pvc }}"}
  monitoring_step: 15
- name: measurements.cluster.pv_stats.test.{{pvc}}.used_bytes
  monitoring_query: kubelet_volume_stats_used_bytes{persistentvolumeclaim="{{ pvc }}"}
  monitoring_step: 15
- name: measurements.cluster.pv_stats.test.{{pvc}}.available_bytes
  monitoring_query: kubelet_volume_stats_available_bytes{persistentvolumeclaim="{{ pvc }}"}
  monitoring_step: 15
{%- endmacro %}

{{ pv_stats('data-rhdh-postgresql-primary-0') }}

# Collect index usage
#Note: It is assumed that the default value forÂ namespace and pod name is used.
- name: measurements.postgresql.backstage-plugin-catalog.index
  command: oc exec rhdh-postgresql-primary-0 -n rhdh-performance -- psql -h localhost -U postgres backstage_plugin_catalog -c "SELECT relname, 100 * idx_scan / (seq_scan + idx_scan) percent_of_times_index_used, n_live_tup rows_in_table FROM pg_stat_user_tables ORDER BY n_live_tup DESC;" -A -F ',' |head -n -1|yq -p csv -o json
  output: json

- name: measurements.postgresql.backstage-plugin-auth.index
  command: oc exec rhdh-postgresql-primary-0 -n rhdh-performance -- psql -h localhost -U postgres backstage_plugin_auth -c "SELECT relname, 100 * idx_scan / (seq_scan + idx_scan) percent_of_times_index_used, n_live_tup rows_in_table FROM pg_stat_user_tables ORDER BY n_live_tup DESC;" -A -F ',' |head -n -1|yq -p csv -o json
  output: json

- name: measurements.postgresql.backstage-plugin-app.index
  command: oc exec rhdh-postgresql-primary-0 -n rhdh-performance -- psql -h localhost -U postgres backstage_plugin_app -c "SELECT relname, 100 * idx_scan / (seq_scan + idx_scan) percent_of_times_index_used, n_live_tup rows_in_table FROM pg_stat_user_tables ORDER BY n_live_tup DESC;" -A -F ',' |head -n -1|yq -p csv -o json
  output: json

- name: measurements.postgresql.backstage-plugin-scaffolder.index
  command: oc exec rhdh-postgresql-primary-0 -n rhdh-performance -- psql -h localhost -U postgres backstage_plugin_scaffolder -c "SELECT relname, 100 * idx_scan / (seq_scan + idx_scan) percent_of_times_index_used, n_live_tup rows_in_table FROM pg_stat_user_tables ORDER BY n_live_tup DESC;" -A -F ',' |head -n -1|yq -p csv -o json
  output: json

- name: measurements.postgresql.backstage-plugin-search.index
  command: oc exec rhdh-postgresql-primary-0 -n rhdh-performance -- psql -h localhost -U postgres backstage_plugin_search -c "SELECT relname, 100 * idx_scan / (seq_scan + idx_scan) percent_of_times_index_used, n_live_tup rows_in_table FROM pg_stat_user_tables ORDER BY n_live_tup DESC;" -A -F ',' |head -n -1|yq -p csv -o json
  output: json

# Results
{%macro results_scenario(name) -%}
- name: results.{{name}}.locust_requests_avg_response_time
  monitoring_query: sum(locust_requests_avg_response_time{name="{{name}}"})
  monitoring_step: 15
- name: results.{{name}}.locust_requests_avg_content_length
  monitoring_query: sum(locust_requests_avg_content_length{name="{{name}}"})
  monitoring_step: 15
- name: results.{{name}}.locust_requests_current_rps
  monitoring_query: sum(locust_requests_current_rps{name="{{name}}"})
  monitoring_step: 15
- name: results.{{name}}.locust_requests_current_fail_per_sec
  monitoring_query: sum(locust_requests_current_fail_per_sec{name="{{name}}"})
  monitoring_step: 15
- name: results.{{name}}.locust_requests_num_failures
  monitoring_query: sum(locust_requests_num_failures{name="{{name}}"})
  monitoring_step: 15
- name: results.{{name}}.locust_errors
  monitoring_query: sum(locust_errors{name="{{name}}"})
  monitoring_step: 15
{%- endmacro %}

- name: results.locust_requests_fail_ratio
  monitoring_query: locust_requests_fail_ratio
  monitoring_step: 15
- name: results.locust_users
  monitoring_query: locust_users
  monitoring_step: 15

{{ results_scenario('Aggregated') }}
