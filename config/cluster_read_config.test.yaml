- name: measurements.cluster_cpu_usage_seconds_total_rate
  monitoring_query: sum(node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate{cluster=""})
  monitoring_step: 15

- name: measurements.cluster_memory_usage_rss_total
  monitoring_query: sum(container_memory_rss{job="kubelet", metrics_path="/metrics/cadvisor", cluster="", container!=""})
  monitoring_step: 15

- name: measurements.cluster_disk_throughput_total
  monitoring_query: sum (rate(container_fs_reads_bytes_total{id!="", device=~"(/dev.+)|mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+", cluster=""}[5m]) + rate(container_fs_writes_bytes_total{id!="", device=~"(/dev.+)|mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+", cluster=""}[5m]))
  monitoring_step: 15

- name: measurements.cluster_network_bytes_total
  monitoring_query: sum(irate(container_network_receive_bytes_total{cluster="",namespace=~".*"}[5m])) + sum(irate(container_network_transmit_bytes_total{cluster="",namespace=~".*"}[5m]))
  monitoring_step: 15

- name: measurements.cluster_network_receive_bytes_total
  monitoring_query: sum(irate(container_network_receive_bytes_total{cluster="",namespace=~".*"}[5m]))
  monitoring_step: 15

- name: measurements.cluster_network_transmit_bytes_total
  monitoring_query: sum(irate(container_network_transmit_bytes_total{cluster="",namespace=~".*"}[5m]))
  monitoring_step: 15

- name: measurements.node_disk_io_time_seconds_total
  monitoring_query: sum(irate(node_disk_io_time_seconds_total{cluster="",namespace=~".*"}[5m]))
  monitoring_step: 15

- name: measurements.cluster_nodes_worker_count
  monitoring_query: count(kube_node_role{role="worker"})
  monitoring_step: 15

- name: measurements.cluster_pods_count
  monitoring_query: count(kube_pod_info)
  monitoring_step: 15

- name: measurements.cluster_running_pods_on_workers_count
  monitoring_query: count(kube_pod_info * on(node) group_left(role) kube_node_role{role="worker"} and on(pod, namespace) (kube_pod_status_phase{job="kube-state-metrics", phase="Running"} > 0))
  monitoring_step: 15

- name: measurements.etcd_request_duration_seconds_average
  monitoring_query: sum(rate(etcd_request_duration_seconds_sum{}[5m])) / sum(rate(etcd_request_duration_seconds_count[5m]))
  monitoring_step: 15

# Interesting CI environment variables
{% for var in [
  'BUILD_ID',
  'BASE_HOST',
  'HOSTNAME',
  'JOB_NAME',
  'OPENSHIFT_API',
  'PROW_JOB_ID',
  'PULL_BASE_REF',
  'PULL_BASE_SHA',
  'PULL_HEAD_REF',
  'PULL_NUMBER',
  'PULL_PULL_SHA',
  'PULL_REFS',
  'REPO_NAME',
  'REPO_OWNER',
  'USERS',
  'WORKERS',
  'DURATION',
  'SPAWN_RATE',
  'SCENARIO',
  'PRE_LOAD_DB',
  'RHDH_DEPLOYMENT_REPLICAS',
  'RHDH_DB_REPLICAS',
  'RHDH_DB_STORAGE',
  'RHDH_RESOURCES_CPU_REQUESTS',
  'RHDH_RESOURCES_CPU_LIMITS',
  'RHDH_RESOURCES_MEMORY_REQUESTS',
  'RHDH_RESOURCES_MEMORY_LIMITS',
  'RHDH_KEYCLOAK_REPLICAS',
  'RHDH_HELM_REPO',
  'RHDH_HELM_CHART',
  'RHDH_HELM_CHART_VERSION',
  'RHDH_HELM_RELEASE_NAME',
  'RHDH_IMAGE_REGISTRY',
  'RHDH_IMAGE_REPO',
  'RHDH_IMAGE_TAG',
  'API_COUNT',
  'COMPONENT_COUNT',
  'BACKSTAGE_USER_COUNT',
  'GROUP_COUNT',
  'RBAC_POLICY',
  'RBAC_POLICY_SIZE',
  'WAIT_FOR_SEARCH_INDEX',
  'SCALE_WORKERS',
  'SCALE_ACTIVE_USERS_SPAWN_RATES',
  'SCALE_BS_USERS_GROUPS',
  'SCALE_CATALOG_SIZES',
  'SCALE_REPLICAS',
  'SCALE_DB_STORAGES'
] %}
- name: metadata.env.{{ var }}
  env_variable: {{ var }}
{% endfor %}

- name: metadata.git.last_commit.hash
  command: git log -1 --pretty=format:"%H"



# Gather some basic info about the cluster
- name: metadata.cluster.context
  command: oc project default > /dev/null && oc config current-context

- name: metadata.cluster.control-plane.count
  command: oc get nodes -l node-role.kubernetes.io/master -o name | wc -l

- name: metadata.cluster.control-plane.flavor
  command: oc get nodes -l node-role.kubernetes.io/master -o json | jq --raw-output '.items | map(.metadata.labels."beta.kubernetes.io/instance-type") | unique | sort | join(",")'

- name: metadata.cluster.control-plane.nodes
  command: oc get nodes -l node-role.kubernetes.io/master -o json | jq '.items | map(.metadata.name)'
  output: json

- name: metadata.cluster.compute-nodes.count
  command: oc get nodes -l node-role.kubernetes.io/worker -o name | wc -l

- name: metadata.cluster.compute-nodes.flavor
  command: oc get nodes -l node-role.kubernetes.io/worker -o json | jq --raw-output '.items | map(.metadata.labels."beta.kubernetes.io/instance-type") | unique | sort | join(",")'

- name: metadata.cluster.compute-nodes.nodes
  command: oc get nodes -l node-role.kubernetes.io/worker -o json | jq '.items | map(.metadata.name)'
  output: json



{% macro monitor_pod(alias, namespace_regex, pod_regex, step=15, pod_suffix_regex='-[0-9a-f]+-.*') -%}
# Gather monitoring data about the pod
- name: measurements.{{ alias }}.cpu
  monitoring_query: sum(pod:container_cpu_usage:sum{namespace=~'{{ namespace_regex }}', pod=~'{{ pod_regex }}{{ pod_suffix_regex }}'})
  monitoring_step: {{ step }}
- name: measurements.{{ alias }}.memory
  monitoring_query: sum(container_memory_usage_bytes{namespace=~'{{ namespace_regex }}', pod=~'{{ pod_regex }}{{ pod_suffix_regex }}', container!='POD', container!=''})
  monitoring_step: {{ step }}
- name: measurements.{{ alias }}.network_throughput
  monitoring_query: sum( rate(container_network_transmit_bytes_total{namespace=~'{{ namespace_regex }}', pod=~'{{ pod_regex }}{{ pod_suffix_regex }}'}[{{ step * 4 }}s]) + rate(container_network_receive_bytes_total{namespace=~'{{ namespace_regex }}', pod=~'{{ pod_regex }}{{ pod_suffix_regex }}'}[{{ step * 4 }}s]) )
  monitoring_step: {{ step * 4 }}
- name: measurements.{{ alias }}.network_drop
  monitoring_query: sum( rate(container_network_transmit_packets_dropped_total{namespace=~'{{ namespace_regex }}', pod=~'{{ pod_regex }}{{ pod_suffix_regex }}'}[{{ step * 4 }}s]) + rate(container_network_receive_packets_dropped_total{namespace=~'{{ namespace_regex }}', pod=~'{{ pod_regex }}{{ pod_suffix_regex }}'}[{{ step * 4 }}s]) )
  monitoring_step: {{ step * 4 }}
- name: measurements.{{ alias }}.disk_throughput
  monitoring_query: sum( sum(rate(container_fs_reads_bytes_total{namespace=~'{{ namespace_regex }}', pod=~'{{ pod_regex }}{{ pod_suffix_regex }}', device!='/dev/dm-0'}[{{ step * 4 }}s])) + sum(rate(container_fs_writes_bytes_total{namespace=~'{{ namespace_regex }}', pod=~'{{ pod_regex }}{{ pod_suffix_regex }}', device!='/dev/dm-0'}[{{ step * 4 }}s])) )
  monitoring_step: {{ step * 4 }}
- name: measurements.{{ alias }}.restarts
  monitoring_query: sum(kube_pod_container_status_restarts_total{namespace=~'{{ namespace_regex }}', pod=~'{{ pod_regex }}{{ pod_suffix_regex }}'})
  monitoring_step: {{ step }}
- name: measurements.{{ alias }}.count_ready
  monitoring_query: sum( kube_pod_status_ready{namespace=~'{{ namespace_regex }}', pod=~'{{ pod_regex }}{{ pod_suffix_regex }}'} )
  monitoring_step: {{ step }}
{%- endmacro %}

{% macro pod_info(alias, namespace_regex, deployment_regex, container) -%}
# Gather info about pod configuration
- name: metadata.cluster.pods.{{ alias }}.count
  command: oc get deployments -A -o json | jq -r '.items[] | select(.metadata.namespace | match("{{ namespace_regex }}")) | select(.metadata.name | match("{{ deployment_regex }}")).spec | if has("replicas") then .replicas else 1 end'
- name: metadata.cluster.pods.{{ alias }}.resources
  command: oc get deployments -A -o json | jq -r '.items[] | select(.metadata.namespace | match("{{ namespace_regex }}")) | select(.metadata.name | match("{{ deployment_regex }}")).spec.template.spec.containers | map(select(.name == "{{ container }}"))[0].resources'
  output: json
- name: metadata.cluster.pods.{{ alias }}.image
  command: oc get deployments -A -o json | jq -r '.items[] | select(.metadata.namespace | match("{{ namespace_regex }}")) | select(.metadata.name | match("{{ deployment_regex }}")).spec.template.spec.containers | map(select(.name == "{{ container }}"))[0].image'
- name: metadata.cluster.pods.{{ alias }}.image_tag
  command: oc get deployments -A -o json | jq -r '.items[] | select(.metadata.namespace | match("{{ namespace_regex }}")) | select(.metadata.name | match("{{ deployment_regex }}")).spec.template.spec.containers | map(select(.name == "{{ container }}"))[0].image | split(":")[1]'
{%- endmacro %}



# Collect data for relevant pods
{{ monitor_pod('rhdh-developer-hub', '${RHDH_NAMESPACE}', '(rhdh|backstage)-developer-hub', 15) }}
{{ monitor_pod('rhdh-postgresql', '${RHDH_NAMESPACE}', '(rhdh|backstage)-(postgresql|psql)', 15, '-.*') }}
{{ pod_info('rhdh-developer-hub-backstage-backend', '${RHDH_NAMESPACE}', '(rhdh|backstage)-developer-hub', 'backstage-backend') }}



# Collect data for API pods
{{ monitor_pod('apiserver', 'openshift-apiserver', 'apiserver', 15) }}
{{ monitor_pod('kube-apiserver', 'openshift-kube-apiserver', 'kube-apiserver', 15, pod_suffix_regex='-ip-.+') }}

{% macro pv_stats(alias, pvc_regex) -%}
# Collect data for PV stats
- name: measurements.cluster.pv_stats.test.{{alias}}.capacity_bytes
  monitoring_query: kubelet_volume_stats_capacity_bytes{persistentvolumeclaim=~"{{ pvc_regex }}", namespace="${RHDH_NAMESPACE}"}
  monitoring_step: 15
- name: measurements.cluster.pv_stats.test.{{alias}}.used_bytes
  monitoring_query: kubelet_volume_stats_used_bytes{persistentvolumeclaim=~"{{ pvc_regex }}", namespace="${RHDH_NAMESPACE}"}
  monitoring_step: 15
- name: measurements.cluster.pv_stats.test.{{alias}}.available_bytes
  monitoring_query: kubelet_volume_stats_available_bytes{persistentvolumeclaim=~"{{ pvc_regex }}", namespace="${RHDH_NAMESPACE}"}
  monitoring_step: 15
{%- endmacro %}

{{ pv_stats('rhdh-postgresql', 'data-(rhdh|backstage)-(postgresql|psql)-(primary|developer-hub)-0') }}

# Results
{%macro results_scenario(name) -%}
- name: results.{{name}}.locust_requests_avg_response_time
  monitoring_query: sum(locust_requests_avg_response_time{name="{{name}}", namespace="${LOCUST_NAMESPACE}"})
  monitoring_step: 15
- name: results.{{name}}.locust_requests_avg_content_length
  monitoring_query: sum(locust_requests_avg_content_length{name="{{name}}", namespace="${LOCUST_NAMESPACE}"})
  monitoring_step: 15
- name: results.{{name}}.locust_requests_current_rps
  monitoring_query: sum(locust_requests_current_rps{name="{{name}}", namespace="${LOCUST_NAMESPACE}"})
  monitoring_step: 15
- name: results.{{name}}.locust_requests_current_fail_per_sec
  monitoring_query: sum(locust_requests_current_fail_per_sec{name="{{name}}", namespace="${LOCUST_NAMESPACE}"})
  monitoring_step: 15
- name: results.{{name}}.locust_requests_num_failures
  monitoring_query: sum(locust_requests_num_failures{name="{{name}}", namespace="${LOCUST_NAMESPACE}"})
  monitoring_step: 15
- name: results.{{name}}.locust_errors
  monitoring_query: sum(locust_errors{name="{{name}}", namespace="${LOCUST_NAMESPACE}"})
  monitoring_step: 15
{%- endmacro %}

- name: results.locust_requests_fail_ratio
  monitoring_query: locust_requests_fail_ratio{namespace="${LOCUST_NAMESPACE}"}
  monitoring_step: 15
- name: results.locust_users
  monitoring_query: locust_users{namespace="${LOCUST_NAMESPACE}"}
  monitoring_step: 15

{{ results_scenario('Aggregated') }}
