{% macro pv_stats(alias, pvc_regex) -%}
# Collect data for PV stats
- name: measurements.cluster.pv_stats.populate.{{alias}}.capacity_bytes
  monitoring_query: kubelet_volume_stats_capacity_bytes{persistentvolumeclaim=~"{{ pvc_regex }}"}
  monitoring_step: 15
- name: measurements.cluster.pv_stats.populate.{{alias}}.used_bytes
  monitoring_query: kubelet_volume_stats_used_bytes{persistentvolumeclaim=~"{{ pvc_regex }}"}
  monitoring_step: 15
- name: measurements.cluster.pv_stats.populate.{{alias}}.available_bytes
  monitoring_query: kubelet_volume_stats_available_bytes{persistentvolumeclaim=~"{{ pvc_regex }}"}
  monitoring_step: 15
{%- endmacro %}

{{ pv_stats('rhdh-postgresql', 'data-(rhdh|backstage)-(postgresql|psql)-(primary|developer-hub)-0') }}

{% macro rhdh_nodejs_rate( query ) -%}
# Gather nodejs monitoring data about the {{ query }}
- name: measurements.nodejs.populate.{{ query }}
  monitoring_query: sum(rate({{ query }}{ job="rhdh-metrics" }[5m]))
  monitoring_step: 15
{%- endmacro %}

{% for query in [
'process_cpu_user_seconds_total',
'process_cpu_system_seconds_total',
'process_cpu_seconds_total',
'catalog_stitched_entities_count'
] %}
{{ rhdh_nodejs_rate(query) }}
{% endfor %}


{% macro rhdh_nodejs( query ) -%}
# Gather nodejs monitoring data about the {{ query }}
- name: measurements.nodejs.populate.{{ query }}
  monitoring_query: sum({{ query }}{ job="rhdh-metrics" })
  monitoring_step: 15
{%- endmacro %}

{% for query in [
'process_resident_memory_bytes',
'process_virtual_memory_bytes',
'process_heap_bytes',
'process_open_fds',
'nodejs_eventloop_lag_seconds',
'nodejs_eventloop_lag_mean_seconds',
'nodejs_eventloop_lag_stddev_seconds',
'nodejs_eventloop_lag_p90_seconds',
'nodejs_active_resources_total',
'nodejs_active_handles_total',
'nodejs_active_requests_total',
'nodejs_heap_size_total_bytes',
'nodejs_heap_size_used_bytes',
'nodejs_external_memory_bytes',
'catalog_registered_locations_count',
'catalog_relations_count',
'catalog_processing_queue_delay_seconds_sum',
'catalog_processing_queue_delay_seconds_count'
] %}
{{ rhdh_nodejs(query) }}
{% endfor %}

{% macro rhdh_nodejs_lst( query, label, valuelst) -%}
{% for value  in valuelst %}
# Gather nodejs monitoring data about the {{ query }}
- name: measurements.nodejs.populate.{{ query }}.{{ label }}.{{ 
value }}
  monitoring_query: sum({{ query }}{ {{ label }}="{{ value }}", job="rhdh-metrics" })
  monitoring_step: 15
{% endfor %}
{%- endmacro %}

{{ rhdh_nodejs_lst('catalog_processors_duration_seconds_sum', 'result', ['ok','failed']) }}
{{ rhdh_nodejs_lst('catalog_processors_duration_seconds_count', 'result', ['ok','failed']) }}
{{ rhdh_nodejs_lst('catalog_processing_duration_seconds_sum', 'result', ['unchanged']) }}
{{ rhdh_nodejs_lst('catalog_processing_duration_seconds_count', 'result', ['unchanged']) }}
{{ rhdh_nodejs_lst('nodejs_gc_duration_seconds_sum', 'kind', ['minor','major','incremental']) }}
{{ rhdh_nodejs_lst('nodejs_gc_duration_seconds_count', 'kind', ['minor','major','incremental']) }}
{{ rhdh_nodejs_lst('catalog_entities_count', 'kind', ['location','user','group']) }}

- name: measurements.nodejs.populate.catalog_processing_queue_delay_seconds_average
  monitoring_query: sum(rate(catalog_processing_queue_delay_seconds_sum{job="rhdh-metrics"}[5m]))/sum(rate(catalog_processing_queue_delay_seconds_count{job="rhdh-metrics"}[5m]))
  monitoring_step: 15

- name: measurements.nodejs.populate.catalog_processors_duration_seconds_failed_average
  monitoring_query: sum(rate(catalog_processors_duration_seconds_sum{result="failed",job="rhdh-metrics"}[5m]))/sum(rate(catalog_processors_duration_seconds_count{result="failed",job="rhdh-metrics"}[5m]))
  monitoring_step: 15

- name: measurements.nodejs.populate.nodejs_gc_duration_seconds_major_average
  monitoring_query: sum(rate(nodejs_gc_duration_seconds_sum{kind="major",job="rhdh-metrics"}[5m]))/sum(rate(nodejs_gc_duration_seconds_count{kind="major",job="rhdh-metrics"}[5m]))
  monitoring_step: 15


{% macro pg_query_sum(alias, query) -%}
# Gather monitoring data about the db {{ alias }}
- name: measurements.postgresql.populate.{{ alias }}.{{ query }}
  monitoring_query: sum({{ query }}{service='{{ alias }}-prometheus-postgres-exporter'})
  monitoring_step: 15
{%- endmacro %}

{% for query in [
'pg_statio_user_indexes_idx_blks_hit_total',
'pg_statio_user_indexes_idx_blks_read_total',
'pg_statio_user_tables_heap_blocks_hit',
'pg_statio_user_tables_heap_blocks_read',
'pg_statio_user_tables_idx_blocks_hit',
'pg_statio_user_tables_idx_blocks_read',
'pg_statio_user_tables_tidx_blocks_hit',
'pg_statio_user_tables_tidx_blocks_read',
'pg_statio_user_tables_toast_blocks_hit',
'pg_statio_user_tables_toast_blocks_read',
'pg_stat_user_tables_vacuum_count',
'pg_stat_user_tables_size_bytes',
'pg_stat_user_tables_seq_tup_read',
'pg_stat_user_tables_seq_scan',
'pg_stat_user_tables_n_tup_upd',
'pg_stat_user_tables_n_tup_ins',
'pg_stat_user_tables_n_tup_hot_upd',
'pg_stat_user_tables_n_tup_del',
'pg_stat_user_tables_n_mod_since_analyze',
'pg_stat_user_tables_n_live_tup',
'pg_stat_user_tables_n_dead_tup',
'pg_stat_user_tables_last_vacuum',
'pg_stat_user_tables_last_autovacuum',
'pg_stat_user_tables_last_autoanalyze',
'pg_stat_user_tables_last_analyze',
'pg_stat_user_tables_idx_tup_fetch',
'pg_stat_user_tables_idx_scan',
'pg_stat_user_tables_autovacuum_count',
'pg_stat_user_tables_autoanalyze_count',
'pg_stat_user_tables_analyze_count'
] %}
{% for db in [
'backstage-plugin-permission',
'backstage-plugin-auth',
'backstage-plugin-catalog',
'backstage-plugin-scaffolder',
'backstage-plugin-search',
'backstage-plugin-app'
] %}
{{ pg_query_sum(db, query ) }}
{% endfor %}
{% endfor %}

{% macro pg_query(alias, query) -%}
# Gather monitoring data about the db {{ alias }}
- name: measurements.postgresql.populate.{{ alias }}.{{ query }}
  monitoring_query: {{ query }}{datname="{{ alias }}"}
  monitoring_step: 15
{%- endmacro %}

{% for query in [
'pg_stat_database_blk_read_time',
'pg_stat_database_blk_write_time',
'pg_stat_database_blks_hit',
'pg_stat_database_blks_read',
'pg_stat_database_conflicts',
'pg_stat_database_conflicts_confl_bufferpin',
'pg_stat_database_conflicts_confl_deadlock',
'pg_stat_database_conflicts_confl_lock',
'pg_stat_database_conflicts_confl_snapshot',
'pg_stat_database_conflicts_confl_tablespace',
'pg_stat_database_deadlocks',
'pg_stat_database_numbackends',
'pg_stat_database_temp_bytes',
'pg_stat_database_temp_files',
'pg_stat_database_tup_deleted',
'pg_stat_database_tup_fetched',
'pg_stat_database_tup_inserted',
'pg_stat_database_tup_returned',
'pg_stat_database_tup_updated',
'pg_stat_database_xact_commit',
'pg_stat_database_xact_rollback',
'pg_database_size_bytes'
] %}
{% for db in [
'backstage_plugin_permission',
'backstage_plugin_auth',
'backstage_plugin_catalog',
'backstage_plugin_scaffolder',
'backstage_plugin_search',
'backstage_plugin_app'
] %}
{{ pg_query(db, query ) }}
{% endfor %}
{% endfor %}

{% macro pg_stat_statements_sum(alias, query) -%}
# Gather monitoring data about the db {{ alias }}
- name: measurements.postgresql.populate.{{ alias }}.{{ query }}
  monitoring_query: sum({{ query }}{datname='{{ alias }}'})
  monitoring_step: 15
{%- endmacro %}

{% for query in [
'pg_stat_statements_block_read_seconds_total',
'pg_stat_statements_block_write_seconds_total',
'pg_stat_statements_calls_total',
'pg_stat_statements_rows_total',
'pg_stat_statements_seconds_total',
'pg_locks_count'
] %}
{% for db in [
'backstage_plugin_permission',
'backstage_plugin_auth',
'backstage_plugin_catalog',
'backstage_plugin_scaffolder',
'backstage_plugin_search',
'backstage_plugin_app'
] %}
{{ pg_stat_statements_sum(db, query ) }}
{% endfor %}
{% endfor %}


{% macro pg_settings(query) -%}
# Gather monitoring data about the db {{ alias }}
- name: measurements.postgresql.populate.{{ query }}
  monitoring_query: {{ query }}{service="pg-exporter-prometheus-postgres-exporter"}
  monitoring_step: 30
{%- endmacro %}

{% for query in [
'pg_settings_max_connections',
'pg_settings_superuser_reserved_connections',
'pg_settings_shared_buffers_bytes',
'pg_settings_work_mem_bytes',
'pg_settings_maintenance_work_mem_bytes',
'pg_settings_shared_memory_size_in_huge_pages',
'pg_settings_effective_cache_size_bytes',
'pg_settings_effective_io_concurrency',
'pg_settings_random_page_cost',
'pg_settings_track_io_timing',
'pg_settings_max_wal_senders',
'pg_settings_checkpoint_timeout_seconds',
'pg_settings_checkpoint_completion_target',
'pg_settings_max_wal_size_bytes',
'pg_settings_min_wal_size_bytes',
'pg_settings_wal_buffers_bytes',
'pg_settings_wal_writer_delay_seconds',
'pg_settings_wal_writer_flush_after_bytes',
'pg_settings_bgwriter_delay_seconds',
'pg_settings_bgwriter_lru_maxpages',
'pg_settings_bgwriter_lru_multiplier',
'pg_settings_bgwriter_flush_after_bytes',
'pg_settings_max_worker_processes',
'pg_settings_max_parallel_workers_per_gather',
'pg_settings_max_parallel_maintenance_workers',
'pg_settings_max_parallel_workers',
'pg_settings_parallel_leader_participation',
'pg_settings_enable_partitionwise_join',
'pg_settings_enable_partitionwise_aggregate',
'pg_settings_jit',
'pg_settings_max_slot_wal_keep_size_bytes',
'pg_settings_track_wal_io_timing',
'pg_settings_maintenance_io_concurrency',
'pg_settings_wal_recycle',
'pg_process_idle_seconds_sum',
'pg_process_idle_seconds_count',
'pg_stat_bgwriter_buffers_alloc_total',
'pg_stat_bgwriter_buffers_backend_fsync_total',
'pg_stat_bgwriter_buffers_backend_total',
'pg_stat_bgwriter_buffers_checkpoint_tota',
'pg_stat_bgwriter_buffers_clean_total',
'pg_stat_bgwriter_checkpoint_sync_time_total',
'pg_stat_bgwriter_checkpoint_write_time_total',
'pg_stat_bgwriter_checkpoints_req_total',
'pg_stat_bgwriter_checkpoints_timed_total',
'pg_stat_bgwriter_maxwritten_clean_total',
'pg_stat_archiver_archived_count',
'pg_stat_archiver_failed_count',
'pg_long_running_transactions',
'pg_long_running_transactions_oldest_timestamp_seconds',
'pg_wal_segments',
'pg_wal_size_bytes',
'process_cpu_seconds_total',
'process_max_fds',
'process_open_fds',
'process_resident_memory_bytes',
'process_virtual_memory_bytes',
'process_virtual_memory_max_bytes',
] %}
{{ pg_settings( query ) }}
{% endfor %}

{% macro pg_stat_activity(alias, query, state) -%}
# Gather monitoring data about the db {{ alias }}
- name: measurements.postgresql.populate.{{ alias }}.{{ query }}.{{ state }}
  monitoring_query: sum({{ query }}{datname='{{ alias }}',state='{{ state }}',service="pg-exporter-prometheus-postgres-exporter"})
  monitoring_step: 15
{%- endmacro %}

{% for query in [
'pg_stat_activity_count',
'pg_stat_activity_max_tx_duration'
] %}
{% for db in [
'backstage_plugin_permission',
'backstage_plugin_auth',
'backstage_plugin_catalog',
'backstage_plugin_scaffolder',
'backstage_plugin_search',
'backstage_plugin_app'
] %}
{% for state in [
'active',
'disabled',
'fastpath',
'idle'
] %}
{{ pg_stat_activity(db, query, state ) }}
{% endfor %}
{% endfor %}
{% endfor %}
