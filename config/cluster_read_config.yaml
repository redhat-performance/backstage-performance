- name: measurements.cluster_cpu_usage_seconds_total_rate
  monitoring_query: sum(node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate{cluster=""})
  monitoring_step: 15

- name: measurements.cluster_memory_usage_rss_total
  monitoring_query: sum(container_memory_rss{job="kubelet", metrics_path="/metrics/cadvisor", cluster="", container!=""})
  monitoring_step: 15

- name: measurements.cluster_disk_throughput_total
  monitoring_query: sum (rate(container_fs_reads_bytes_total{id!="", device=~"(/dev.+)|mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+", cluster=""}[5m]) + rate(container_fs_writes_bytes_total{id!="", device=~"(/dev.+)|mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+", cluster=""}[5m]))
  monitoring_step: 15

- name: measurements.cluster_network_bytes_total
  monitoring_query: sum(irate(container_network_receive_bytes_total{cluster="",namespace=~".*"}[5m])) + sum(irate(container_network_transmit_bytes_total{cluster="",namespace=~".*"}[5m]))
  monitoring_step: 15

- name: measurements.cluster_network_receive_bytes_total
  monitoring_query: sum(irate(container_network_receive_bytes_total{cluster="",namespace=~".*"}[5m]))
  monitoring_step: 15

- name: measurements.cluster_network_transmit_bytes_total
  monitoring_query: sum(irate(container_network_transmit_bytes_total{cluster="",namespace=~".*"}[5m]))
  monitoring_step: 15

- name: measurements.node_disk_io_time_seconds_total
  monitoring_query: sum(irate(node_disk_io_time_seconds_total{cluster="",namespace=~".*"}[5m]))
  monitoring_step: 15

- name: measurements.cluster_nodes_worker_count
  monitoring_query: count(kube_node_role{role="worker"})
  monitoring_step: 15

- name: measurements.cluster_pods_count
  monitoring_query: count(kube_pod_info)
  monitoring_step: 15

- name: measurements.cluster_running_pods_on_workers_count
  monitoring_query: count(kube_pod_info * on(node) group_left(role) kube_node_role{role="worker"} and on(pod, namespace) (kube_pod_status_phase{job="kube-state-metrics", phase="Running"} > 0))
  monitoring_step: 15

- name: measurements.etcd_request_duration_seconds_average
  monitoring_query: sum(rate(etcd_request_duration_seconds_sum{}[5m])) / sum(rate(etcd_request_duration_seconds_count[5m]))
  monitoring_step: 15



# Interesting CI environment variables
{% for var in [
  'BUILD_ID',
  'HOSTNAME',
  'JOB_NAME',
  'OPENSHIFT_API',
  'PROW_JOB_ID',
  'PULL_BASE_REF',
  'PULL_BASE_SHA',
  'PULL_HEAD_REF',
  'PULL_NUMBER',
  'PULL_PULL_SHA',
  'PULL_REFS',
  'REPO_NAME',
  'REPO_OWNER',
  'USERS',
  'WORKERS',
  'DURATION',
  'SCENARIO',
] %}
- name: metadata.env.{{ var }}
  env_variable: {{ var }}
{% endfor %}

- name: metadata.git.last_commit.hash
  command: git log -1 --pretty=format:"%H"



# Gather some basic info about the cluster
- name: metadata.cluster.context
  command: oc project default > /dev/null && oc config current-context

- name: metadata.cluster.control-plane.count
  command: oc get nodes -l node-role.kubernetes.io/master -o name | wc -l

- name: metadata.cluster.control-plane.flavor
  command: oc get nodes -l node-role.kubernetes.io/master -o json | jq --raw-output '.items | map(.metadata.labels."beta.kubernetes.io/instance-type") | unique | sort | join(",")'

- name: metadata.cluster.control-plane.nodes
  command: oc get nodes -l node-role.kubernetes.io/master -o json | jq '.items | map(.metadata.name)'
  output: json

- name: metadata.cluster.compute-nodes.count
  command: oc get nodes -l node-role.kubernetes.io/worker -o name | wc -l

- name: metadata.cluster.compute-nodes.flavor
  command: oc get nodes -l node-role.kubernetes.io/worker -o json | jq --raw-output '.items | map(.metadata.labels."beta.kubernetes.io/instance-type") | unique | sort | join(",")'

- name: metadata.cluster.compute-nodes.nodes
  command: oc get nodes -l node-role.kubernetes.io/worker -o json | jq '.items | map(.metadata.name)'
  output: json



{% macro monitor_pod(namespace, pod, step=15, pod_suffix_regex='-[0-9a-f]+-.*') -%}
# Gather monitoring data about the pod
- name: measurements.{{ pod }}.cpu
  monitoring_query: sum(pod:container_cpu_usage:sum{namespace='{{ namespace }}', pod=~'{{ pod }}{{ pod_suffix_regex }}'})
  monitoring_step: {{ step }}
- name: measurements.{{ pod }}.memory
  monitoring_query: sum(container_memory_usage_bytes{namespace='{{ namespace }}', pod=~'{{ pod }}{{ pod_suffix_regex }}', container!='POD', container!=''})
  monitoring_step: {{ step }}
- name: measurements.{{ pod }}.network_throughput
  monitoring_query: sum( rate(container_network_transmit_bytes_total{namespace='{{ namespace }}', pod=~'{{ pod }}{{ pod_suffix_regex }}'}[{{ step * 4 }}s]) + rate(container_network_receive_bytes_total{namespace='{{ namespace }}', pod=~'{{ pod }}{{ pod_suffix_regex }}'}[{{ step * 4 }}s]) )
  monitoring_step: {{ step * 4 }}
- name: measurements.{{ pod }}.network_drop
  monitoring_query: sum( rate(container_network_transmit_packets_dropped_total{namespace='{{ namespace }}', pod=~'{{ pod }}{{ pod_suffix_regex }}'}[{{ step * 4 }}s]) + rate(container_network_receive_packets_dropped_total{namespace='{{ namespace }}', pod=~'{{ pod }}{{ pod_suffix_regex }}'}[{{ step * 4 }}s]) )
  monitoring_step: {{ step * 4 }}
- name: measurements.{{ pod }}.disk_throughput
  monitoring_query: sum( sum(rate(container_fs_reads_bytes_total{namespace='{{ namespace }}', pod=~'{{ pod }}{{ pod_suffix_regex }}', device!='/dev/dm-0'}[{{ step * 4 }}s])) + sum(rate(container_fs_writes_bytes_total{namespace='{{ namespace }}', pod=~'{{ pod }}{{ pod_suffix_regex }}', device!='/dev/dm-0'}[{{ step * 4 }}s])) )
  monitoring_step: {{ step * 4 }}
- name: measurements.{{ pod }}.restarts
  monitoring_query: sum(kube_pod_container_status_restarts_total{namespace='{{ namespace }}', pod=~'{{ pod }}{{ pod_suffix_regex }}'})
  monitoring_step: {{ step }}
- name: measurements.{{ pod }}.count_ready
  monitoring_query: sum( kube_pod_status_ready{namespace='{{ namespace }}', pod=~'{{ pod }}{{ pod_suffix_regex }}'} )
  monitoring_step: {{ step }}
{%- endmacro %}

{% macro pod_info(namespace, deployment, container) -%}
# Gather info about pod configuration
- name: metadata.cluster.pods.{{ deployment }}-{{ container }}.count
  command: oc -n {{ namespace }} get deployment/{{ deployment }} -o json | jq '.spec.template.spec | if has("replicas") then .replicas else 1 end'
- name: metadata.cluster.pods.{{ deployment }}-{{ container }}.resources
  command: oc -n {{ namespace }} get deployment/{{ deployment }} -o json | jq '.spec.template.spec.containers | map(select(.name == "{{ container }}"))[0].resources'
  output: json
- name: metadata.cluster.pods.{{ deployment }}-{{ container }}.image
  command: oc -n {{ namespace }} get deployment/{{ deployment }} -o json | jq --raw-output '.spec.template.spec.containers | map(select(.name == "{{ container }}"))[0].image'
- name: metadata.cluster.pods.{{ deployment }}-{{ container }}.image_tag
  command: oc -n {{ namespace }} get deployment/{{ deployment }} -o json | jq --raw-output '.spec.template.spec.containers | map(select(.name == "{{ container }}"))[0].image | split(":")[1]'
{%- endmacro %}



# Collect data for relevant pods
{{ monitor_pod('rhdh-performance', 'rhdh-developer-hub', 15) }}
{{ monitor_pod('rhdh-performance', 'rhdh-postgresql', 15, '-.*') }}
{{ pod_info('rhdh-performance', 'rhdh-developer-hub', 'backstage-backend') }}



# Collect data for API pods
{{ monitor_pod('openshift-apiserver', 'apiserver', 15) }}
{{ monitor_pod('openshift-kube-apiserver', 'kube-apiserver', 15, pod_suffix_regex='-ip-.+') }}



# Results
- name: results.locust-operator.locust_requests_avg_response_time_Aggregated
  monitoring_query: sum(locust_requests_avg_response_time{name="Aggregated"})
  monitoring_step: 15
- name: results.locust-operator.locust_requests_avg_content_length_Aggregated
  monitoring_query: sum(locust_requests_avg_content_length{name="Aggregated"})
  monitoring_step: 15
- name: results.locust-operator.locust_requests_current_rps_Aggregated
  monitoring_query: sum(locust_requests_current_rps{name="Aggregated"})
  monitoring_step: 15
- name: results.locust-operator.locust_requests_fail_ratio_Aggregated
  monitoring_query: sum(locust_requests_fail_ratio)
  monitoring_step: 15
